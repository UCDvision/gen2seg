# gen2seg: Generative Models Enable Generalizable Instance Segmentation
[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/reachomk/gen2seg)


### [Project Page](https://reachomk.github.io/gen2seg) | [Paper](https://arxiv.org/abs/...)


[**gen2seg: Generative Models Enable Generalizable Instance Segmentation**](https://reachomk.github.io/gen2seg)  
 [Om Khangaonkar](https://reachomk.github.io),
 [Hamed Pirsiavash](https://web.cs.ucdavis.edu/~hpirsiav/)<br>
 UC Davis <br>
<img src='assets/teaser.png'/>

## Pretrained Models
Stable Diffusion 2 (SD): https://huggingface.co/reachomk/gen2seg-sd

ImageNet-1K-pretrained Masked Autoencoder-Huge (MAE-H):  https://huggingface.co/reachomk/gen2seg-mae-h

If you want any of our other models, send me an email. If there is sufficent demand, I will also release them publicly. 

##  Inference
Currently, we have released inference code for our SD and MAE models. You can run them by editing the `image_path` variable (for your input image) in each file, and then simply running it with `python inference_{mae or sd}.py`.  

You will need to have `transformers` and `diffusers` installed, along with standard machine learning packages such as `pytorch` and `numpy`.  More details on our specific environment will be released with the training code. 

We have also released code for prompting. Please run `pip install opencv-contrib-python` prior to running this file. 

Here is how you run it:
```
python prompting.py \
    --feature_image /path/to/your/feature_image.png \
    --prompt_x 150 \ 
    --prompt_y 200 \
```
The feature image is the one generated by our model, NOT the original image. 


We also have the additional optional arguments:
```
--output_mask /path/to/save/output_mask.png \
--sigma 0.02 \
--threshold 10
```

Threshold and sigma allow you to control the mask threshold (out of 255) and the amount of averaging for the query vector. By default they are 0.01 and 3. See our paper for more details. 

We have also provided our inference script for SAM, to enable qualitative comparison. Please make sure you download the checkpoint and input the path in the script. You should also edit the `image_path` variable (for your input image). 

## Training
I will release all training code by June 7 (likely earlier). Make sure to star and watch our repository so you're notified when we update it! Send me an email if you need it before that. 

##  Citation
Please cite our paper if it was helpful or you liked it. 
